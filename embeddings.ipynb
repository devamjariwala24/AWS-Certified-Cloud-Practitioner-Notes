{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devamjariwala24/AWS-Certified-Cloud-Practitioner-Notes/blob/master/embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDsn_Motja8Q"
      },
      "source": [
        "# Cross-Language Word Embeddings\n",
        "\n",
        "In class, we discussed how we can reduce the dimensionality of word representations from their original vector space to an embedding space on the order of a few hundred dimensions. Different modeling choices for word embeddings may be ultimately evaluated by the effectiveness of classification or retrieval models.\n",
        "\n",
        "In this assignment, however, we will consider another common method of evaluating word embeddings: by judging the usefulness of pairwise distances between words in the embedding space.\n",
        "\n",
        "Follow along with the examples in this notebook, and implement the sections of code flagged with **TODO**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip uninstall scipy -y"
      ],
      "metadata": {
        "id": "WZ3XDzXiQTOR",
        "outputId": "6d5f5db3-95e2-4993-92d8-0afc05fc32c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: scipy 1.13.1\n",
            "Uninstalling scipy-1.13.1:\n",
            "  Successfully uninstalled scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --no-cache-dir\n",
        "!pip install scipy==1.13.1 --no-cache-dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZdnysxxZgiW",
        "outputId": "116c04d9-d536-448e-9d03-0e99285045a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "qdldl 0.1.7.post5 requires scipy>=0.13.2, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "shap 0.47.0 requires scipy, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\n",
            "scs 3.2.7.post2 requires scipy, which is not installed.\n",
            "mizani 0.13.1 requires scipy>=1.8.0, which is not installed.\n",
            "umap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "pytensor 2.28.3 requires scipy<2,>=1, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\n",
            "osqp 0.6.7.post3 requires scipy>=0.13.2, which is not installed.\n",
            "pynndescent 0.5.13 requires scipy>=1.0, which is not installed.\n",
            "sentence-transformers 3.4.1 requires scipy, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "clarabel 0.10.0 requires scipy, which is not installed.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "xgboost 2.1.4 requires scipy, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "pymc 5.21.1 requires scipy>=1.4.1, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy==1.13.1) (1.26.4)\n",
            "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m227.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "Successfully installed scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## If you already have gensim, you can comment this out.\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "Q1lmDByzHu66",
        "outputId": "339d6edc-3856-40fc-a182-92e3ba3c40e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKm5cPMQ2xHU"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfKjYFDklB4c"
      },
      "source": [
        "We'll start by downloading a plain-text version of the plays of William Shakespeare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3bvl1yf5FB",
        "outputId": "8059abb1-26d6-44e7-eb3a-b821bde3f25c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt\n",
        "lines = [s.split() for s in open('shakespeare_plays.txt')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 00:43:45--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4746840 (4.5M) [text/plain]\n",
            "Saving to: ‘shakespeare_plays.txt.1’\n",
            "\n",
            "shakespeare_plays.t 100%[===================>]   4.53M  9.07MB/s    in 0.5s    \n",
            "\n",
            "2025-03-28 00:43:46 (9.07 MB/s) - ‘shakespeare_plays.txt.1’ saved [4746840/4746840]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cZ52pEflKKM"
      },
      "source": [
        "Then, we'll estimate a simple word2vec model on the Shakespeare texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXT5BNPs_zjM"
      },
      "source": [
        "model = Word2Vec(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzt3lG1-lw33"
      },
      "source": [
        "Even with such a small training set size, you can perform some standard analogy\n",
        "tasks we discussed in class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ruAqhKC3-R",
        "outputId": "8eb70ec2-cc87-4473-9f21-47bd0f96680a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.wv.most_similar(positive=['king','woman'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7669879198074341),\n",
              " ('prince', 0.7248110175132751),\n",
              " ('duke', 0.7217379808425903),\n",
              " ('clarence', 0.7165194749832153),\n",
              " ('york', 0.708121657371521),\n",
              " ('warwick', 0.7045184373855591),\n",
              " ('cardinal', 0.6906446218490601),\n",
              " ('son', 0.6822353005409241),\n",
              " ('princess', 0.6643941402435303),\n",
              " ('northumberland', 0.6581059098243713)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJL45y5emjA9"
      },
      "source": [
        "In other words, we want a vector close to `king` and `woman` but subtracting the dimensions that are important to `man`, i.e., `queen`. Other words are mostly noble titles important in Shakespeare's \"history\" plays.\n",
        "\n",
        "For the rest of this assignment, we will focus on finding words with similar embeddings, both within and across languages. For example, what words are similar to the name of the title character of *Othello*?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EZGroU0KPyj",
        "outputId": "b185da9e-9e87-4fb8-8fe6-a2b1ae0fb292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.wv.most_similar(positive=['othello'])\n",
        "#model.wv.most_similar(positive=['brutus'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('desdemona', 0.9690727591514587),\n",
              " ('emilia', 0.9156944751739502),\n",
              " ('iago', 0.909894585609436),\n",
              " ('ham', 0.8952130675315857),\n",
              " ('cassio', 0.8951020240783691),\n",
              " ('countess', 0.8919875025749207),\n",
              " ('cressida', 0.8913081884384155),\n",
              " ('pisanio', 0.8838783502578735),\n",
              " ('cleopatra', 0.8810870051383972),\n",
              " ('imogen', 0.8807059526443481)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2BT_7zZle3"
      },
      "source": [
        "If you know the play, you might see some familiar names.\n",
        "\n",
        "This search uses cosine similarity. In the default API, you should see the same similarity between the words `othello` and `desdemona` as in the search results above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e32-u4zYFda",
        "outputId": "0b6493d3-d54e-443b-e3a9-3da4812f7ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.wv.similarity('othello', 'desdemona')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9690728"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49DwfAmZ6PU"
      },
      "source": [
        "**TODO**: Your **first task**, therefore, is to implement your own cosine similarity function so that you can reuse it outside of the context of the gensim model object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEj2PqpuZ5xs",
        "outputId": "7200809a-ca52-4df1-a098-4f44926a9d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## TODO: Implement cosim\n",
        "import numpy as np\n",
        "def cosim(v1, v2):\n",
        "  dot_product = np.dot(v1, v2)\n",
        "  np_v1_norm = np.linalg.norm(v1)\n",
        "  np_v2_norm = np.linalg.norm(v2)\n",
        "\n",
        "  cos_product = dot_product / (np_v1_norm * np_v2_norm)\n",
        "  return cos_product\n",
        "\n",
        "## This should give a result similar to model.wv.similarity:\n",
        "cosim_ans = cosim(model.wv['othello'], model.wv['desdemona'])\n",
        "print(cosim_ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9690728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TbDqBIHbHfB"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We could collect a lot of human judgments about how similar pairs of words, or pairs of Shakespearean characters, are. Then we could compare different word-embedding models by their ability to replicate these human judgments.\n",
        "\n",
        "If we extend our ambition to multiple languages, however, we can use a word translation task to evaluate word embeddings.\n",
        "\n",
        "We will use a subset of [Facebook AI's FastText cross-language embeddings](https://fasttext.cc/docs/en/aligned-vectors.html) for several languages. Your task will be to compare English both to French, and to *one more language* from the following set: Arabic, German, Portuguese, Russian, Spanish, Vietnamese, and Chinese."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC_FXRnfq1BO",
        "outputId": "7bf67197-aa10-4865-e98f-229ce603d51b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec\n",
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec\n",
        "\n",
        "# TODO: uncomment at least one of these to work with another language\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ar.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.de.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.pt.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ru.vec\n",
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.es.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.vi.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.zh.vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 00:43:59--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67681172 (65M)\n",
            "Saving to: ‘30k.en.vec.1’\n",
            "\n",
            "30k.en.vec.1        100%[===================>]  64.54M  38.2MB/s    in 1.7s    \n",
            "\n",
            "2025-03-28 00:44:01 (38.2 MB/s) - ‘30k.en.vec.1’ saved [67681172/67681172]\n",
            "\n",
            "--2025-03-28 00:44:01--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67802327 (65M)\n",
            "Saving to: ‘30k.fr.vec.1’\n",
            "\n",
            "30k.fr.vec.1        100%[===================>]  64.66M  38.1MB/s    in 1.7s    \n",
            "\n",
            "2025-03-28 00:44:03 (38.1 MB/s) - ‘30k.fr.vec.1’ saved [67802327/67802327]\n",
            "\n",
            "--2025-03-28 00:44:03--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.es.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67762853 (65M) [application/ecmascript]\n",
            "Saving to: ‘30k.es.vec.1’\n",
            "\n",
            "30k.es.vec.1        100%[===================>]  64.62M  38.4MB/s    in 1.7s    \n",
            "\n",
            "2025-03-28 00:44:04 (38.4 MB/s) - ‘30k.es.vec.1’ saved [67762853/67762853]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmuIvGpNrJPe"
      },
      "source": [
        "We'll start by loading the word vectors from their textual file format to a dictionary mapping words to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbWORXkP2Vvn"
      },
      "source": [
        "def vecref(s):\n",
        "  (word, srec) = s.split(' ', 1)\n",
        "  return (word, np.fromstring(srec, sep=' '))\n",
        "\n",
        "def ftvectors(fname):\n",
        "  return { k:v for (k, v) in [vecref(s) for s in open(fname)] if len(v) > 1}\n",
        "\n",
        "envec = ftvectors('30k.en.vec')\n",
        "frvec = ftvectors('30k.fr.vec')\n",
        "\n",
        "# TODO: load vectors for one more language, such as zhvec (Chinese)\n",
        "# arvec = ftvectors('30k.ar.vec')\n",
        "# devec = ftvectors('30k.de.vec')\n",
        "# ptvec = ftvectors('30k.pt.vec')\n",
        "# ruvec = ftvectors('30k.ru.vec')\n",
        "esvec = ftvectors('30k.es.vec')\n",
        "# vivec = ftvectors('30k.vi.vec')\n",
        "# zhvec = ftvectors('30k.zh.vec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j88E1JdueZHc"
      },
      "source": [
        "**TODO**: Your next task is to write a simple function that takes a vector and a dictionary of vectors and finds the most similar item in the dictionary. For this part of the assignment, a linear scan through the dictionary using your `cosim` function from above is acceptible."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mostSimilar(vec, vecDict):\n",
        "    mostSimilar = ''\n",
        "    max_similarity = -1\n",
        "\n",
        "    for word, word_vec in vecDict.items():\n",
        "        similarity = cosim(vec, word_vec)\n",
        "\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            mostSimilar = word\n",
        "\n",
        "    return (mostSimilar, max_similarity)"
      ],
      "metadata": {
        "id": "BGoS5JGFBrCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_words = ['computer', 'germany', 'matrix', 'physics', 'yeast']\n",
        "results = [mostSimilar(envec[e], frvec) for e in test_words]\n",
        "for word, result in zip(test_words, results):\n",
        "    print(f\"Most similar to '{word}': {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE7O42jXCvrr",
        "outputId": "48e7f758-fc76-4584-8dfb-7e7555d400cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar to 'computer': ('informatique', 0.5023827767603765)\n",
            "Most similar to 'germany': ('allemagne', 0.593718413875964)\n",
            "Most similar to 'matrix': ('matrice', 0.5088361302065517)\n",
            "Most similar to 'physics': ('physique', 0.4555543434796394)\n",
            "Most similar to 'yeast': ('fermentation', 0.3504105196166514)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[mostSimilar(envec[e], esvec) for e in ['computer', 'germany', 'matrix', 'physics', 'yeast']]"
      ],
      "metadata": {
        "id": "J8fO0cbJBnSr",
        "outputId": "bdc0bcd5-02ab-4d6f-c974-404661722edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('computador', 0.5013697495254124),\n",
              " ('alemania', 0.6352798713596078),\n",
              " ('matriz', 0.4784864671614966),\n",
              " ('física', 0.4784845095690361),\n",
              " ('levadura', 0.5114917452709493)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dance_in_spanish = mostSimilar(envec['dance'], esvec)\n",
        "print(dance_in_spanish)"
      ],
      "metadata": {
        "id": "oQydKOpwBtrl",
        "outputId": "23c1b2ba-7c9c-48b0-f4b2-a3e68f2c85da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('baile', 0.5620383041003675)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIKUD5qxpUMB"
      },
      "source": [
        "Some matches make more sense than others. Note that `computer` most closely matches `informatique`, the French term for *computer science*. If you looked further down the list, you would see `ordinateur`, the term for *computer*. This is one weakness of a focus only on embeddings for word *types* independent of context.\n",
        "\n",
        "To evalute cross-language embeddings more broadly, we'll look at a dataset of links between Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az10sIFwsEUP",
        "outputId": "55f75d1d-2e92-4eee-81cc-ee6774f3a586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab\n",
        "links = [s.split() for s in open('links.tab')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 00:44:12--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1408915 (1.3M)\n",
            "Saving to: ‘links.tab.1’\n",
            "\n",
            "links.tab.1         100%[===================>]   1.34M  3.10MB/s    in 0.4s    \n",
            "\n",
            "2025-03-28 00:44:13 (3.10 MB/s) - ‘links.tab.1’ saved [1408915/1408915]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqHq0hFCv8NY"
      },
      "source": [
        "This `links` variable consists of triples of `(English term, language, term in that language)`. For example, here is the link between English `academy` and French `académie`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7eusdxtdsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d54852d-0f49-4f89-a11c-a548c423ff9a"
      },
      "source": [
        "links[302]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['academy', 'fr', 'académie']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct a test set for English-French from the first 1000 links between those languages."
      ],
      "metadata": {
        "id": "oA85pbt3JL1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frtest = [x for x in links if x[1] == \"fr\"][0:1000]\n",
        "frtest[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuYkUbkYIwSb",
        "outputId": "ea5e76b6-e59e-43d5-8397-6bb818965bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['aalborg', 'fr', 'aalborg'],\n",
              " ['aarhus', 'fr', 'aarhus'],\n",
              " ['aba', 'fr', 'aba'],\n",
              " ['abad', 'fr', 'abad'],\n",
              " ['abandon', 'fr', 'abandon'],\n",
              " ['abbas', 'fr', 'abbas'],\n",
              " ['abbasid', 'fr', 'abbassides'],\n",
              " ['abbess', 'fr', 'abbesse'],\n",
              " ['abbey', 'fr', 'abbaye'],\n",
              " ['abbot', 'fr', 'abbé']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYEdOQbmwql3"
      },
      "source": [
        "**TODO**: Evaluate the English and French embeddings by computing the proportion of English Wikipedia articles whose corresponding French article in this test set `frtest` is also the closest word in embedding space. Skip English articles not covered by the word embedding dictionary.\n",
        "\n",
        "Since many articles, e.g., about named entities, have the same title in English and French, use the identity function as a baseline and compute its accuracy. In other words, how often would you find the right French articles by simply echoing the English title as if it were French? In the ten example links above, `aalborg` and `aarhus` (two cities in Denmark) are the same in English and French. Remember to iterate only over the 1000 linked Wikipedia articles in the test set, not the entire embedding dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I have followed this approach: We will iterate through the 1000 words of frtest and estest, if we get the word in the embedding, then only we wil consider that to be a valid link. This way, we will have real accuracy where accuracy is found by dividing with the number of valid links and not 1000, because if we divide it by 1000, then we will also be including those words which are skipped. By dividing with valid links, we include only those words for which we found in embedding."
      ],
      "metadata": {
        "id": "dsKUyauyv7Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "accuracy = 0\n",
        "baselineAccuracy = 0\n",
        "valid_links = 0\n",
        "exact_word_matches = 0\n",
        "word_pairs_dict = {}\n",
        "\n",
        "for link in tqdm(frtest, total=len(frtest), desc=\"Processing Links\", unit=\"link\"):\n",
        "    english_word = link[0]\n",
        "    french_word = link[2]\n",
        "    word_pairs_dict[english_word] = french_word\n",
        "\n",
        "    if english_word in envec:\n",
        "        valid_links += 1\n",
        "        most_similar_french_word, _ = mostSimilar(envec[english_word], frvec)\n",
        "        if most_similar_french_word == french_word:\n",
        "            accuracy += 1\n",
        "\n",
        "        if english_word == french_word:\n",
        "            baselineAccuracy += 1\n",
        "            exact_word_matches += 1\n",
        "\n",
        "if valid_links > 0:\n",
        "    accuracy_percentage = (accuracy / valid_links) * 100\n",
        "    print(\"\\n\")\n",
        "    print(f\"\\nPrecision@1 for french is {accuracy_percentage:.2f}%\")\n",
        "    baseline_accuracy_percentage = (baselineAccuracy / valid_links) * 100\n",
        "    print(f\"Baseline Accuracy for french is {baseline_accuracy_percentage:.2f}%\")\n",
        "else:\n",
        "    print(\"No valid links found with both embeddings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlYS-XD5AI2",
        "outputId": "500b0f91-f2c9-49fa-b0cf-d496647d1991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Links: 100%|██████████| 1000/1000 [03:43<00:00,  4.47link/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Precision@1 for french is 57.50%\n",
            "Baseline Accuracy for french is 66.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hqd1buq-OEo"
      },
      "source": [
        "**TODO**: Compute the accuracy, i.e. precision@1, of the embeddings and of the identity function for the first 1000 links between English and another language besides French. Although the baseline will be lower for languages not written in the Roman alphabet (i.e., Arabic or Chinese), there are still many articles in those languages with headwords written in Roman characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnKtHya-jmj"
      },
      "source": [
        "## TODO: Compute English-X Wikipedia retrieval accuracy.\n",
        "estest = [x for x in links if x[1] == \"es\"][0:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "baselineAccuracy = 0\n",
        "valid_links = 0\n",
        "\n",
        "for link in tqdm(estest, total=len(estest), desc=\"Processing Links\", unit=\"link\"):\n",
        "    english_word = link[0]\n",
        "    spanish_word = link[2]\n",
        "\n",
        "    if english_word in envec:\n",
        "        valid_links += 1\n",
        "        most_similar_spanish_word, _ = mostSimilar(envec[english_word], esvec)\n",
        "        if most_similar_spanish_word == spanish_word:\n",
        "            accuracy += 1\n",
        "\n",
        "        if english_word == spanish_word:\n",
        "            baselineAccuracy += 1\n",
        "\n",
        "if valid_links > 0:\n",
        "    accuracy_percentage = (accuracy / valid_links) * 100\n",
        "    print(\"\\n\")\n",
        "    print(f\"\\nPrecision@1 for spanish is {accuracy_percentage:.2f}%\")\n",
        "    baseline_accuracy_percentage = (baselineAccuracy / valid_links) * 100\n",
        "    print(f\"Baseline Accuracy for spanish is {baseline_accuracy_percentage:.2f}%\")\n",
        "else:\n",
        "    print(\"No valid links found with both embeddings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGL46Qoo3JqP",
        "outputId": "a999099f-0cd2-498f-c145-f3b88e674380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Links: 100%|██████████| 1000/1000 [03:45<00:00,  4.44link/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Precision@1 for spanish is 53.60%\n",
            "Baseline Accuracy for spanish is 51.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6z01sufFPJh"
      },
      "source": [
        "**TODO**: Find the 10 nearest neighbors of each English term to compute \"recall at 10\" and \"mean reciprocal rank at 10\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Compute recall@10 and MRR@10 when retrieving 10 nearest neighbors in French and some other language."
      ],
      "metadata": {
        "id": "TgAORWTQl0Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import heapq\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_top_10_nearest_neighbors(word_vector, vec_dict):\n",
        "    similarities = [(word, cosim(word_vector, vec)) for word, vec in vec_dict.items()]\n",
        "    return heapq.nlargest(10, similarities, key=lambda x: x[1])\n",
        "\n",
        "def process_links(test_links, envec, vec_dict, lang_type):\n",
        "    valid_links = 0\n",
        "    missing_embeddings = 0\n",
        "    recall_at_10 = 0\n",
        "    mrr_at_10 = 0\n",
        "    top_10_neighbors_dict = defaultdict(list)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for link in tqdm(test_links, total=len(test_links), desc=f\"Processing {lang_type} Links\", unit=\"link\"):\n",
        "        english_word = link[0]\n",
        "        target_word = link[2]\n",
        "\n",
        "        if english_word in envec:\n",
        "            valid_links += 1\n",
        "            top_10_neighbors_dict[english_word] = get_top_10_nearest_neighbors(envec[english_word], vec_dict)\n",
        "        else:\n",
        "            missing_embeddings += 1\n",
        "\n",
        "    time_taken = time.time() - start_time\n",
        "\n",
        "    for link in tqdm(test_links, total=len(test_links), desc=f\"Calculating MRR & Recall for {lang_type}\", unit=\"link\"):\n",
        "        english_word = link[0]\n",
        "        target_word = link[2]\n",
        "\n",
        "        if english_word in top_10_neighbors_dict:\n",
        "            top_10_neighbors = top_10_neighbors_dict[english_word]\n",
        "            top_10_words = [neighbor[0] for neighbor in top_10_neighbors]\n",
        "\n",
        "            if target_word in top_10_words:\n",
        "                recall_at_10 += 1\n",
        "\n",
        "            for rank, (word, _) in enumerate(top_10_neighbors, start=1):\n",
        "                if word == target_word:\n",
        "                    mrr_at_10 += 1 / rank\n",
        "                    break\n",
        "\n",
        "    recall_at_10_percentage = recall_at_10 / valid_links if valid_links > 0 else 0\n",
        "    mrr_at_10_average = mrr_at_10 / valid_links if valid_links > 0 else 0\n",
        "\n",
        "    return recall_at_10_percentage, mrr_at_10_average, time_taken, missing_embeddings\n",
        "\n",
        "recall_at_10_spanish, mrr_at_10_spanish, time_taken_spanish, missing_embeddings_spanish = process_links(estest, envec, esvec, \"Spanish\")\n",
        "recall_at_10_french, mrr_at_10_french, time_taken_french, missing_embeddings_french = process_links(frtest, envec, frvec, \"French\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"\\nRecall@10 for Spanish: {recall_at_10_spanish:.2f}\")\n",
        "print(f\"MRR@10 for Spanish: {mrr_at_10_spanish:.2f}\")\n",
        "print(f\"\\nRecall@10 for French: {recall_at_10_french:.2f}\")\n",
        "print(f\"MRR@10 for French: {mrr_at_10_french:.2f}\")\n",
        "print(f\"\\nTime taken to compute top 10 neighbors for Spanish: {time_taken_spanish:.4f} seconds\")\n",
        "print(f\"Time taken to compute top 10 neighbors for French: {time_taken_french:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_VMUWQ23kh0",
        "outputId": "72fbd5e7-bce0-45e8-d7fa-837264a2fdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Spanish Links: 100%|██████████| 1000/1000 [03:56<00:00,  4.22link/s]\n",
            "Calculating MRR & Recall for Spanish: 100%|██████████| 1000/1000 [00:00<00:00, 169227.52link/s]\n",
            "Processing French Links: 100%|██████████| 1000/1000 [03:55<00:00,  4.26link/s]\n",
            "Calculating MRR & Recall for French: 100%|██████████| 1000/1000 [00:00<00:00, 164147.78link/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Recall@10 for Spanish: 0.61\n",
            "MRR@10 for Spanish: 0.56\n",
            "\n",
            "Recall@10 for French: 0.64\n",
            "MRR@10 for French: 0.60\n",
            "\n",
            "Time taken to compute top 10 neighbors for Spanish: 236.9498 seconds\n",
            "Time taken to compute top 10 neighbors for French: 235.0180 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speeding up Vector Search (required for CS6200, 20 points extra for IS4200)\n",
        "\n",
        "The list of Wikipedia headwords is short enough that a linear scan through the non-English language embeddings takes some time but is feasible. In a production system, you could index the word embeddings using SimHash or some other locality sensitive hashing scheme, as we discussed for duplicate detection, to speed up this process.\n",
        "\n",
        "A relatively easy way to get started with fast vector similarity search is to install Meta's `faiss` (Facebook AI Similarity Search) package and read [the tutorial](https://github.com/facebookresearch/faiss/wiki/Getting-started)."
      ],
      "metadata": {
        "id": "GsXoZaVsYMXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outside of colab, you may need a different package manager.\n",
        "# !apt install libomp-dev\n",
        "!pip install --upgrade faiss-cpu\n",
        "# Use this line instead if you have a GPU.\n",
        "# !python -m pip install --upgrade faiss-gpu\n",
        "import faiss"
      ],
      "metadata": {
        "id": "KSJ-c9PDKHaD",
        "outputId": "8d18a736-6bfc-4780-83ef-517abf25670a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: Create two vector indexes, for the FastText embeddings of French and for the other language you evaluated above. Use `faiss` to find the 10 nearest neighbors for the top 1000 Wikipedia headwords you evaluated for English-French and the English-X as above.\n",
        "\n",
        "First, measure the _effectiveness_ of this approximate vector search approach. How does the R@10 and MRR@10 using `faiss` compare to the brute-force search you did above?\n",
        "\n",
        "Second, measure the _efficiency_ of this approach. How long in seconds does finding nearest neighbors for 1000 headwords by brute force compare to using `faiss`? (For this exercise, don't worry about amortizing indexing costs.)"
      ],
      "metadata": {
        "id": "hfr0buVwLz-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def embeddings_to_numpy(embeddings_dict):\n",
        "    words = list(embeddings_dict.keys())\n",
        "    vectors = np.array([embeddings_dict[word] for word in words])\n",
        "    return words, vectors\n",
        "\n",
        "def create_faiss_index(embeddings_dict):\n",
        "    words, vectors = embeddings_to_numpy(embeddings_dict)\n",
        "    index = faiss.IndexFlatL2(vectors.shape[1])\n",
        "    index.add(vectors)\n",
        "    return index, words\n",
        "\n",
        "def faiss_search(query_vector, index, words, k=10):\n",
        "    distances, indices = index.search(np.array([query_vector]), k)\n",
        "    top_k_words = [words[i] for i in indices[0]]\n",
        "    return top_k_words, distances[0]"
      ],
      "metadata": {
        "id": "tenUUYyIGq1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_es, words_es = create_faiss_index(esvec)\n",
        "index_fr, words_fr = create_faiss_index(frvec)"
      ],
      "metadata": {
        "id": "KE2lCI_9GwgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_neighbors_dict = {}\n",
        "french_neighbors_dict = {}\n",
        "\n",
        "start_time_faiss_spanish = time.time()\n",
        "for link in tqdm(estest, total=1000, desc=\"Processing Spanish Links\", unit=\"link\"):\n",
        "    english_word = link[0]\n",
        "    spanish_word = link[2]\n",
        "\n",
        "    if english_word in envec:\n",
        "        english_vector = envec[english_word]\n",
        "        top_10_neighbors_spanish, _ = faiss_search(english_vector, index_es, words_es, k=10)\n",
        "        spanish_neighbors_dict[english_word] = top_10_neighbors_spanish\n",
        "end_time_faiss_spanish = time.time()\n",
        "\n",
        "start_time_faiss_french = time.time()\n",
        "for link in tqdm(frtest, total=1000, desc=\"Processing French Links\", unit=\"link\"):\n",
        "    english_word = link[0]\n",
        "    french_word = link[2]\n",
        "    if english_word in envec:\n",
        "        english_vector = envec[english_word]\n",
        "        top_10_neighbors_french, _ = faiss_search(english_vector, index_fr, words_fr, k=10)\n",
        "        french_neighbors_dict[english_word] = top_10_neighbors_french\n",
        "end_time_faiss_french = time.time()\n",
        "\n",
        "faiss_spanish_time = end_time_faiss_spanish - start_time_faiss_spanish\n",
        "faiss_french_time = end_time_faiss_french - start_time_faiss_french\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"\\nTime taken to compute top 10 neighbors for Spanish FAISS: {faiss_spanish_time:.4f} seconds\")\n",
        "print(f\"Time taken to compute top 10 neighbors for French FAISS: {faiss_french_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLQBpQQ3F377",
        "outputId": "1d1e09d6-e3dd-418d-e564-01131f9d7525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Spanish Links: 100%|██████████| 1000/1000 [00:04<00:00, 232.92link/s]\n",
            "Processing French Links: 100%|██████████| 1000/1000 [00:04<00:00, 219.31link/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Time taken to compute top 10 neighbors for Spanish FAISS: 4.2968 seconds\n",
            "Time taken to compute top 10 neighbors for French FAISS: 4.5633 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mrr_recall(test_set, neighbors_dict, valid_links, embeddings_dict, language):\n",
        "    recall_at_10 = 0\n",
        "    mrr_at_10 = 0\n",
        "    valid_count = 0\n",
        "\n",
        "    for link in tqdm(test_set, total=valid_links, desc=f\"Calculating MRR & Recall for {language}\", unit=\"link\"):\n",
        "        english_word = link[0]\n",
        "        target_word = link[2]\n",
        "\n",
        "        if english_word in embeddings_dict:\n",
        "            valid_count += 1\n",
        "            if english_word in neighbors_dict:\n",
        "                top_10_neighbors = neighbors_dict[english_word]\n",
        "                if target_word in top_10_neighbors:\n",
        "                    recall_at_10 += 1\n",
        "\n",
        "                for rank, word in enumerate(top_10_neighbors, start=1):\n",
        "                    if word == target_word:\n",
        "                        mrr_at_10 += 1 / rank\n",
        "                        break\n",
        "\n",
        "    recall_percentage = recall_at_10 / valid_count if valid_count > 0 else 0\n",
        "    mrr_average = mrr_at_10 / valid_count if valid_count > 0 else 0\n",
        "    return recall_percentage, mrr_average\n",
        "\n",
        "\n",
        "recall_at_10_spanish_percentage, mrr_at_10_spanish_average = calculate_mrr_recall(estest, spanish_neighbors_dict, len(estest), envec, \"Spanish\")\n",
        "recall_at_10_french_percentage, mrr_at_10_french_average = calculate_mrr_recall(frtest, french_neighbors_dict, len(frtest), envec, \"French\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"\\nRecall@10 for Spanish: {recall_at_10_spanish_percentage:.2f}\")\n",
        "print(f\"MRR@10 for Spanish: {mrr_at_10_spanish_average:.2f}\")\n",
        "print(f\"\\nRecall@10 for French: {recall_at_10_french_percentage:.2f}\")\n",
        "print(f\"MRR@10 for French: {mrr_at_10_french_average:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4km5e35DnRI",
        "outputId": "95782a50-3aaf-4dbf-81be-2de991281734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating MRR & Recall for Spanish: 100%|██████████| 1000/1000 [00:00<00:00, 269973.22link/s]\n",
            "Calculating MRR & Recall for French: 100%|██████████| 1000/1000 [00:00<00:00, 380470.25link/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Recall@10 for Spanish: 0.61\n",
            "MRR@10 for Spanish: 0.56\n",
            "\n",
            "Recall@10 for French: 0.64\n",
            "MRR@10 for French: 0.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Time Difference in FAISS as compared to Brute Force (Spanish): {time_taken_spanish - faiss_spanish_time:.2f} seconds\")\n",
        "print(f\"Time Difference in FAISS as compared to Brute Force (French):  {time_taken_french - faiss_french_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "AykH8rdeNH_p",
        "outputId": "24e19ac9-ff97-4de2-f5bf-dd53d5dc6bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Difference in FAISS as compared to Brute Force (Spanish): 232.65 seconds\n",
            "Time Difference in FAISS as compared to Brute Force (French):  230.45 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Effectiveness for MRR@10 and Recall@10 for Brute force as well as FAISS:\n",
        "Recall@10 is similar for both Brute force as well as FAISS. MRR@10 is also same for faiss as compared to brute force\n",
        "\n",
        "\n",
        "## Time Complexity for Brute Force as well as FAISS:\n",
        "The comparison between brute-force search and FAISS shows a remarkable difference in efficiency. This significant improvement is due to FAISS's optimization for fast approximate nearest neighbor search, using efficient indexing techniques that drastically cut down the time complexity. In contrast, brute force has to compare each query to every vector in the dataset, resulting in much longer computation times, especially with larger datasets. The time taken to get through FAISS is nearly 60 times faster than brute force, which is approximaterly 98% faster than brute force.\n",
        "\n"
      ],
      "metadata": {
        "id": "yUMsYvS5LUO1"
      }
    }
  ]
}